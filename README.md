# Simple PDF QA Chatbot

A simple PDF-based Question-Answering chatbot using local LLM (Ollama).

## Quick Start

### Prerequisites

1. **Install Ollama**: [Download from official site](https://ollama.ai/)
2. **Pull LLM model**:
   ```bash
   ollama pull llama3:8b
   ```

### Installation

1. Clone or download this project
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Run the application:
   ```bash
   streamlit run app.py
   ```

## Project Structure

```
simple_pdf_chatbot/
â”œâ”€â”€ app.py               # Main Streamlit application
â”œâ”€â”€ requirements.txt     # Dependencies
â”œâ”€â”€ README.md           # This file
â”œâ”€â”€ .gitignore          # Git ignore rules
â””â”€â”€ config.yaml         # Configuration (optional)
```

## Usage

1. **Upload PDF**: Use the sidebar to upload a PDF document
2. **Process**: Click "PDF ì²˜ë¦¬" to extract and vectorize content
3. **Ask Questions**: Use the chat interface to ask questions about the document
4. **View Sources**: Expand "ì°¸ê³  ë¬¸ì„œ" to see source passages

## Features

- ğŸ”’ **Local Processing**: Uses Ollama for completely local LLM inference
- ğŸ“„ **PDF Support**: Extract and process PDF documents for Q&A
- ğŸŒ **Korean Support**: Optimized for Korean language processing
- ğŸ¨ **Simple UI**: Clean Streamlit interface

## Configuration

You can modify the model settings directly in `app.py` or create a `config.yaml` file.

## License

MIT License
