#!/usr/bin/env python3
"""
FastAPI ê¸°ë°˜ í†µí•© RAG ì‹œìŠ¤í…œ
- unified_rag_cli.pyì™€ ë™ì¼í•œ core ëª¨ë“ˆ import ë°©ì‹ ì‚¬ìš©
- RESTful API ì œê³µ
- ë¹„ë™ê¸° ì²˜ë¦¬ ì§€ì›
"""

import os
import sys
import time
from datetime import datetime
from typing import Optional, Dict, Any, List
from contextlib import asynccontextmanager
import asyncio

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import uvicorn

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

# unified_rag_cli.pyì™€ ë™ì¼í•œ ëª¨ë“ˆ import ë°©ì‹
from core.config import LLM_MODELS, HUGGINGFACE_EMBEDDINGS_AVAILABLE, UPSTAGE_AVAILABLE, OLLAMA_AVAILABLE
from core.models import ModelFactory
from core.rag import create_rag_chain
from core.chat_history import ChatHistoryManager
from utils.elasticsearch import ElasticsearchManager
from langfuse_config import get_langfuse_manager, get_langfuse_callback

# Elasticsearch ê°€ìš©ì„± í™•ì¸
try:
    from elasticsearch import Elasticsearch
    ELASTICSEARCH_AVAILABLE = True
except ImportError:
    ELASTICSEARCH_AVAILABLE = False
    print("âš ï¸ Elasticsearchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install elasticsearch")

# ì „ì—­ RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
rag_system = None


class FastAPIRAGSystem:
    """FastAPIìš© RAG ì‹œìŠ¤í…œ - unified_rag_cli.pyì™€ ë™ì¼í•œ ë¡œì§"""
    
    def __init__(self):
        self.es_manager = None
        self.model_factory = ModelFactory()
        self.rag_chain = None
        self.embedding_model = None
        self.llm_model = None
        self.model_choice = None
        self.top_k = 5
        
        # Langfuse ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.langfuse_manager = get_langfuse_manager()
        
        # ì„¸ì…˜ë³„ ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
        self.session_managers = {}
        self.is_initialized = False
        self.initialization_time = None
    
    def get_chat_manager(self, session_id: str = "default") -> ChatHistoryManager:
        """ì„¸ì…˜ë³„ ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ì ë°˜í™˜"""
        if session_id not in self.session_managers:
            self.session_managers[session_id] = ChatHistoryManager(max_history=10)
        return self.session_managers[session_id]
    
    async def check_dependencies_async(self) -> Dict[str, Any]:
        """ì˜ì¡´ì„± í™•ì¸ (ë¹„ë™ê¸° ë²„ì „)"""
        def _check_dependencies():
            issues = []
            
            if not ELASTICSEARCH_AVAILABLE:
                issues.append("Elasticsearch ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            if not HUGGINGFACE_EMBEDDINGS_AVAILABLE:
                issues.append("HuggingFace ì„ë² ë”© ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # Elasticsearch ì„œë²„ ì—°ê²° í™•ì¸
            try:
                es_manager = ElasticsearchManager()
                is_connected, connection_msg = es_manager.check_connection()
                if not is_connected:
                    issues.append(f"Elasticsearch ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {connection_msg}")
            except Exception as e:
                issues.append(f"Elasticsearch ì—°ê²° ì˜¤ë¥˜: {str(e)}")
            
            # Ollama ì„œë²„ ì—°ê²° í™•ì¸
            try:
                from core.rag import check_ollama_connection
                ollama_connected, ollama_message = check_ollama_connection()
                if not ollama_connected:
                    issues.append(f"Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {ollama_message}")
            except Exception as e:
                issues.append(f"Ollama ì—°ê²° í™•ì¸ ì˜¤ë¥˜: {str(e)}")
            
            return {
                "status": "ok" if not issues else "error",
                "issues": issues,
                "issue_count": len(issues)
            }
        
        return await asyncio.get_event_loop().run_in_executor(None, _check_dependencies)
    
    async def initialize_rag_system_async(self, model_choice: str, top_k: int = 5) -> Dict[str, Any]:
        """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ë¹„ë™ê¸° ë²„ì „)"""
        def _initialize_rag_system():
            try:
                start_time = time.time()
                
                self.model_choice = model_choice
                self.top_k = top_k
                
                # Elasticsearch ê´€ë¦¬ì ì´ˆê¸°í™”
                self.es_manager = ElasticsearchManager()
                
                # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
                self.embedding_model = self.model_factory.create_embedding_model()
                if not self.embedding_model:
                    return {
                        "status": "error",
                        "message": "ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨"
                    }
                
                # LLM ëª¨ë¸ ë¡œë“œ
                self.llm_model, status = self.model_factory.create_llm_model(model_choice)
                if not self.llm_model:
                    return {
                        "status": "error",
                        "message": f"LLM ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {status}"
                    }
                
                # RAG ì²´ì¸ ìƒì„± (Langfuse ì½œë°± í¬í•¨)
                langfuse_callback = get_langfuse_callback()
                callbacks = [langfuse_callback] if langfuse_callback else None
                
                self.rag_chain, success_or_error = create_rag_chain(
                    embeddings=self.embedding_model,
                    llm_model=self.llm_model,
                    top_k=top_k,
                    callbacks=callbacks
                )
                
                if self.rag_chain:
                    self.is_initialized = True
                    self.initialization_time = time.time() - start_time
                    return {
                        "status": "success",
                        "message": "RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ",
                        "model": LLM_MODELS[model_choice]['name'],
                        "top_k": top_k,
                        "initialization_time": self.initialization_time
                    }
                else:
                    return {
                        "status": "error",
                        "message": f"RAG ì²´ì¸ ìƒì„± ì‹¤íŒ¨: {success_or_error}"
                    }
                    
            except Exception as e:
                self.is_initialized = False
                return {
                    "status": "error",
                    "message": f"RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}"
                }
        
        return await asyncio.get_event_loop().run_in_executor(None, _initialize_rag_system)
    
    async def process_query_async(self, query: str, session_id: str = "default") -> Dict[str, Any]:
        """ì§ˆì˜ ì²˜ë¦¬ (ë¹„ë™ê¸° ë²„ì „)"""
        if not self.is_initialized or not self.rag_chain:
            return {
                "status": "error",
                "message": "RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }
        
        def _process_query():
            try:
                start_time = time.time()
                
                # Langfuse íŠ¸ë ˆì´ìŠ¤ ìƒì„±
                trace = self.langfuse_manager.create_trace(
                    name="rag_query",
                    metadata={
                        "session_id": session_id,
                        "model": self.model_choice,
                        "top_k": self.top_k
                    }
                )
                
                # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ì ê°€ì ¸ì˜¤ê¸°
                chat_manager = self.get_chat_manager(session_id)
                
                # RAG ì²´ì¸ì„ í†µí•œ ë‹µë³€ ìƒì„±
                result = self.rag_chain.invoke({"query": query})
                
                # ë””ë²„ê¹…: ì‹¤ì œ ì‘ë‹µ êµ¬ì¡° ì¶œë ¥
                print(f"ğŸ” RAG ì²´ì¸ ì‘ë‹µ êµ¬ì¡°: {result}")
                print(f"ğŸ” ì‘ë‹µ í‚¤ë“¤: {list(result.keys()) if isinstance(result, dict) else 'Not a dict'}")
                
                processing_time = time.time() - start_time
                
                # RetrievalQAëŠ” 'result' í‚¤ë¥¼ ì‚¬ìš©í•¨
                if result and ('answer' in result or 'result' in result):
                    answer = result.get('answer') or result.get('result')
                    
                    # ëŒ€í™” ê¸°ë¡ì— ì§ˆë¬¸ê³¼ ë‹µë³€ ì¶”ê°€
                    chat_manager.add_chat(query, answer)
                    
                    # Langfuseì— ê²°ê³¼ ë¡œê·¸
                    if trace:
                        self.langfuse_manager.log_generation(
                            trace_id=trace.id,
                            name="rag_generation",
                            input=query,
                            output=answer,
                            metadata={
                                "processing_time": processing_time,
                                "retrieved_docs_count": len(result.get('source_documents', [])),
                                "model": self.model_choice
                            }
                        )
                    
                    return {
                        "status": "success",
                        "answer": answer,
                        "query": query,
                        "session_id": session_id,
                        "processing_time": processing_time,
                        "retrieved_docs": result.get('source_documents', [])
                    }
                else:
                    # Langfuseì— ì—ëŸ¬ ë¡œê·¸
                    if trace:
                        self.langfuse_manager.log_event(
                            trace_id=trace.id,
                            name="rag_error",
                            metadata={
                                "error": f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨. ì‘ë‹µ êµ¬ì¡°: {result}",
                                "processing_time": processing_time
                            }
                        )
                    
                    return {
                        "status": "error",
                        "message": f"ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‘ë‹µ êµ¬ì¡°: {result}",
                        "processing_time": processing_time
                    }
                    
            except Exception as e:
                # Langfuseì— ì˜ˆì™¸ ë¡œê·¸
                if 'trace' in locals() and trace:
                    self.langfuse_manager.log_event(
                        trace_id=trace.id,
                        name="rag_exception",
                        metadata={
                            "error": str(e),
                            "processing_time": time.time() - start_time
                        }
                    )
                
                return {
                    "status": "error",
                    "message": f"ì§ˆì˜ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
                    "processing_time": time.time() - start_time
                }
        
        return await asyncio.get_event_loop().run_in_executor(None, _process_query)
    
    def get_system_info(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì •ë³´ ë°˜í™˜"""
        return {
            "is_initialized": self.is_initialized,
            "model": LLM_MODELS.get(self.model_choice, {}).get('name') if self.model_choice else None,
            "model_key": self.model_choice,
            "top_k": self.top_k,
            "initialization_time": self.initialization_time,
            "active_sessions": len(self.session_managers),
            "available_models": self.model_factory.get_available_models(),
            "langfuse_status": self.langfuse_manager.get_status()
        }


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬"""
    # ì‹œì‘ ì‹œ
    global rag_system
    rag_system = FastAPIRAGSystem()
    print("ğŸš€ FastAPI RAG ì‹œìŠ¤í…œ ì‹œì‘")
    
    yield
    
    # ì¢…ë£Œ ì‹œ
    print("ğŸ‘‹ FastAPI RAG ì‹œìŠ¤í…œ ì¢…ë£Œ")


# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="í†µí•© RAG ì‹œìŠ¤í…œ API",
    description="BGE-M3 ì„ë² ë”© + Elasticsearch + ë©€í‹° LLMì„ ì‚¬ìš©í•œ RAG ì‹œìŠ¤í…œ",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Pydantic ëª¨ë¸ ì •ì˜
class QueryRequest(BaseModel):
    query: str = Field(..., description="ì§ˆë¬¸ ë‚´ìš©", min_length=1)
    session_id: str = Field(default="default", description="ì„¸ì…˜ ID")

class InitRequest(BaseModel):
    model: str = Field(..., description="ì‚¬ìš©í•  LLM ëª¨ë¸")
    top_k: int = Field(default=5, description="ê²€ìƒ‰ ê²°ê³¼ ìƒìœ„ Kê°œ", ge=1, le=20)

class ChatHistoryResponse(BaseModel):
    history: List[Dict[str, Any]]
    count: int
    session_id: str


# API ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "í†µí•© RAG ì‹œìŠ¤í…œ API",
        "version": "1.0.0",
        "status": "running"
    }

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    }

@app.get("/dependencies")
async def check_dependencies():
    """ì˜ì¡´ì„± í™•ì¸"""
    result = await rag_system.check_dependencies_async()
    if result["status"] == "error":
        raise HTTPException(status_code=503, detail=result)
    return result

@app.get("/models")
async def get_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡"""
    return {
        "models": rag_system.model_factory.get_available_models(),
        "status": "success"
    }

@app.post("/initialize")
async def initialize_system(request: InitRequest):
    """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    available_models = rag_system.model_factory.get_available_models()
    
    if request.model not in available_models:
        raise HTTPException(
            status_code=400, 
            detail=f"ëª¨ë¸ '{request.model}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {list(available_models.keys())}"
        )
    
    result = await rag_system.initialize_rag_system_async(request.model, request.top_k)
    
    if result["status"] == "error":
        raise HTTPException(status_code=500, detail=result["message"])
    
    return result

@app.get("/status")
async def get_system_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    return rag_system.get_system_info()

@app.post("/query")
async def process_query(request: QueryRequest):
    """ì§ˆì˜ ì²˜ë¦¬"""
    result = await rag_system.process_query_async(request.query, request.session_id)
    
    if result["status"] == "error":
        raise HTTPException(status_code=500, detail=result["message"])
    
    return result

@app.get("/chat/history/{session_id}")
async def get_chat_history(session_id: str = "default"):
    """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
    chat_manager = rag_system.get_chat_manager(session_id)
    
    return ChatHistoryResponse(
        history=chat_manager.get_history(),
        count=chat_manager.get_history_count(),
        session_id=session_id
    )

@app.delete("/chat/history/{session_id}")
async def clear_chat_history(session_id: str = "default"):
    """ëŒ€í™” ê¸°ë¡ ì‚­ì œ"""
    chat_manager = rag_system.get_chat_manager(session_id)
    chat_manager.clear_history()
    
    return {
        "status": "success",
        "message": f"ì„¸ì…˜ '{session_id}'ì˜ ëŒ€í™” ê¸°ë¡ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.",
        "session_id": session_id
    }

@app.get("/sessions")
async def get_active_sessions():
    """í™œì„± ì„¸ì…˜ ëª©ë¡"""
    return {
        "sessions": list(rag_system.session_managers.keys()),
        "count": len(rag_system.session_managers)
    }

@app.delete("/sessions/{session_id}")
async def delete_session(session_id: str):
    """ì„¸ì…˜ ì‚­ì œ"""
    if session_id in rag_system.session_managers:
        del rag_system.session_managers[session_id]
        return {
            "status": "success",
            "message": f"ì„¸ì…˜ '{session_id}'ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    else:
        raise HTTPException(status_code=404, detail=f"ì„¸ì…˜ '{session_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


@app.get("/langfuse/status")
async def get_langfuse_status():
    """Langfuse ìƒíƒœ í™•ì¸"""
    return rag_system.langfuse_manager.get_status()


@app.post("/langfuse/flush")
async def flush_langfuse():
    """Langfuse ë¡œê·¸ ê°•ì œ ì „ì†¡"""
    try:
        rag_system.langfuse_manager.flush()
        return {
            "status": "success",
            "message": "Langfuse ë¡œê·¸ê°€ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Langfuse flush ì‹¤íŒ¨: {str(e)}")


# ì—ëŸ¬ í•¸ë“¤ëŸ¬
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """ì „ì—­ ì˜ˆì™¸ ì²˜ë¦¬"""
    return JSONResponse(
        status_code=500,
        content={
            "status": "error",
            "message": f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜: {str(exc)}",
            "timestamp": datetime.now().isoformat()
        }
    )


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="FastAPI RAG ì‹œìŠ¤í…œ ì„œë²„")
    parser.add_argument("--host", default="127.0.0.1", help="ì„œë²„ í˜¸ìŠ¤íŠ¸")
    parser.add_argument("--port", type=int, default=8000, help="ì„œë²„ í¬íŠ¸")
    parser.add_argument("--reload", action="store_true", help="ìë™ ë¦¬ë¡œë“œ í™œì„±í™”")
    
    args = parser.parse_args()
    
    print(f"ğŸš€ FastAPI RAG ì„œë²„ ì‹œì‘: http://{args.host}:{args.port}")
    print(f"ğŸ“š API ë¬¸ì„œ: http://{args.host}:{args.port}/docs")
    
    uvicorn.run(
        "main:app",
        host=args.host,
        port=args.port,
        reload=args.reload
    )
