#!/usr/bin/python3.11


"""
[TEXT-ONLY CORE] PDF RAG
- ì§€ì • í´ë”ì˜ PDF ì½ê¸°
- Elasticsearch + ë²¡í„° ì„ë² ë”© ìƒ‰ì¸

- python pdf_elasticRAG.py ë¡œ ì‹¤í–‰ ì‹œ, ì„ë² ë”© - ì¸ë±ì‹±.
- python pdf_elasticRAG.py --q "ì§ˆì˜ë‚´ìš©" ìœ¼ë¡œ ì§ˆì˜í•˜ë©´ RAG ì‘ë‹µ
"""

# ===== Imports =====
import os
import sys
import argparse
from dotenv import load_dotenv  # [ë³€ê²½] .env ë¡œë“œ

from elasticsearch import Elasticsearch
from langchain_community.document_loaders import PyPDFLoader  # [TEXT-ONLY]
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.vectorstores import ElasticVectorSearch

# ì‹¤í–‰ ëª¨ë“œ
MODE_GOOGLE = False

# # ===== .env ë¡œë“œ =====
load_dotenv()
if(MODE_GOOGLE):
    GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "")
    if not GOOGLE_API_KEY:
        print("âš ï¸ GOOGLE_API_KEYë¥¼ .env íŒŒì¼ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”.")
    os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY
else:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
    if not OPENAI_API_KEY:
        print("âš ï¸ OPENAI_API_KEYë¥¼ .env íŒŒì¼ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”.")
    os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

if not OPENAI_API_KEY and not GOOGLE_API_KEY:
    print("âš ï¸ ì„¤ì •ëœ AI API KEY ê°€ ì—†ìŠµë‹ˆë‹¤. (GOOGLE_API_KEY / OPENAI_API_KEY) ë¥¼ (.env/í™˜ê²½ë³€ìˆ˜) ë¡œ ì„¤ì •í•˜ì„¸ìš”.")
    print("ì¢…ë£Œí•©ë‹ˆë‹¤....")
    exit(-1)

# ===== Config =====
PDF_DIR = os.getenv("PDF_DIR", "pdf")  # ì½ì„ PDF í´ë”
ELASTICSEARCH_URL = os.getenv("ELASTICSEARCH_URL", "http://localhost:9200")
INDEX_NAME = os.getenv("INDEX_NAME", "pdf_rag")

# ===== CLI =====
parser = argparse.ArgumentParser(description="PDF RAG (í…ìŠ¤íŠ¸ë§Œ â†’ ES ë²¡í„° ìƒ‰ì¸/ì§ˆì˜)")
parser.add_argument("--q", dest="query", type=str, help="ì§ˆì˜ í…ìŠ¤íŠ¸")
parser.add_argument("--k", dest="top_k", type=int, default=9999, help="ê²€ìƒ‰ ìƒìœ„ k (ê¸°ë³¸ 8)")
args = parser.parse_args()

query_mode = args.query is not None
query_text = args.query
top_k = args.top_k


# ===== Helpers =====
def list_pdfs(pdf_dir: str):
    """í´ë” ë‚´ .pdf / .PDF ì „ë¶€ ìˆ˜ì§‘"""
    try:
        names = os.listdir(pdf_dir)
    except FileNotFoundError:
        return []
    files = []
    for name in names:
        if name.lower().endswith(".pdf"):
            p = os.path.join(pdf_dir, name)
            if os.path.isfile(p):
                files.append(os.path.abspath(p))
    return sorted(files)

# def list_pdfs(pdf_dir: str):
#     try:
#         names = os.listdir(pdf_dir)
#     except FileNotFoundError:
#         return []
#     return sorted(
#         os.path.abspath(os.path.join(pdf_dir, n))
#         for n in names
#         if n.lower().endswith(".pdf") and os.path.isfile(os.path.join(pdf_dir, n))
#     )

def total_text_len(docs):
    return sum(len((d.page_content or "").strip()) for d in docs)


        


# def print_sources(docs):
    # print("\nğŸ” Top-k ë¬¸ì„œ ì¶œì²˜:")
    # for i, d in enumerate(docs, 1):
    #     print(f"- #{i}: source={d.metadata.get('source')}, page={d.metadata.get('page_number')}")


# ===== Indexing =====
if not query_mode:
    es = Elasticsearch(ELASTICSEARCH_URL)

    # ì¸ë±ìŠ¤ ì´ˆê¸°í™”(ê¹¨ë—í•˜ê²Œ ì‹œì‘)
    if es.indices.exists(index=INDEX_NAME):
        es.indices.delete(index=INDEX_NAME)

    pdf_files = list_pdfs(PDF_DIR)
    print("ğŸ“„ ëŒ€ìƒ íŒŒì¼:", pdf_files)
    if not pdf_files:
        print(f"âŒ PDF ë””ë ‰í† ë¦¬ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {PDF_DIR}")
        sys.exit(1)

    all_documents = []
    for pdf_path in pdf_files:
        print("file :", pdf_path)

        p = PyPDFLoader(pdf_path)
        docs = p.load()
        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        chunks = splitter.split_documents(docs)
        docs = chunks
        if total_text_len(docs) > 0:
            # ë©”íƒ€ ìµœì†Œ ë³´ê°•
            for d in docs:
                md = d.metadata or {}
                md["category"] = md.get("category", "Text")
                d.metadata = md

        # ë©”íƒ€ë°ì´í„°ì— source/filename ë³´ê°•
        # print("####### extracted by ",loader_used," #######")
        for d in docs:
            # print(d.page_content)
            md = d.metadata or {}
            md["source"] = pdf_path
            md["filename"] = os.path.basename(pdf_path)
            d.metadata = md
        all_documents.extend(docs)
        print(f"docs={len(docs)}, text_len={total_text_len(docs)}")

    if not all_documents:
        print("âŒ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. (ìŠ¤ìº” PDFì¼ ìˆ˜ ìˆìŒ)")
        sys.exit(1)

    if(MODE_GOOGLE):
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    else:
        embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
    ElasticVectorSearch.from_documents(
        all_documents,
        embedding=embeddings,
        elasticsearch_url=ELASTICSEARCH_URL,
        index_name=INDEX_NAME,
    )

    es.indices.refresh(index=INDEX_NAME)
    cnt = es.count(index=INDEX_NAME).get("count", 0)
    print(f"âœ… ìƒ‰ì¸ ì™„ë£Œ. ES ë¬¸ì„œ ìˆ˜: {cnt}")
    print('â¡ï¸ ì§ˆì˜: python script.py --q "ì§ˆë¬¸" --k 8')


# ===== Querying =====
else:
    if(MODE_GOOGLE):
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    else:
        embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
    vectorstore = ElasticVectorSearch(
        embedding=embeddings,
        elasticsearch_url=ELASTICSEARCH_URL,
        index_name=INDEX_NAME,
    )

    retriever = vectorstore.as_retriever(search_kwargs={"k": top_k})
    docs = retriever.invoke(query_text)
    # print_sources(docs)

    if(MODE_GOOGLE):
        llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash")
    else:
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    context = "\n\n".join([d.page_content for d in docs])
    prompt = f"""[ë¬¸ì„œ]
{context}

[ì§ˆë¬¸]
{query_text}

[ì§€ì¹¨]
- ë‹¹ì‹ ì€ ìƒë‹´ì›ì…ë‹ˆë‹¤. ì¹œì ˆí•œ ë§íˆ¬ë¡œ ë‹µí•˜ì„¸ìš”.
- ë¬¸ì„œì— ê·¼ê±°í•´ í•œêµ­ì–´ë¡œ ë‹µí•˜ì„¸ìš”.
- ë¬¸ì„œì— ì •ë³´ê°€ ì—†ê±°ë‚˜ ì• ë§¤í•˜ë©´, ë¬¸ì„œ ë‚´ì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŒì„ ëª…ì‹œí•˜ê³  í•„ìš”í•œ ì¶”ê°€ ì§ˆë¬¸ì„ í•˜ì„¸ìš”.
- ë§ˆì§€ë§‰ì— ì‚¬ìš©í•œ ê·¼ê±°ë¥¼ í•œ ì¤„ë¡œ ìš”ì•½ê³¼ ì‹¤ì œ ë¬¸ì„œ ë‚´ìš© ì¼ë¶€ë¥¼ ë§ˆì§€ë§‰ì— ì œì‹œí•˜ì„¸ìš”.

[ë‹µë³€]"""

    resp = llm.invoke(prompt)
    if(MODE_GOOGLE):
        print("\nğŸ¤– Gemini ì‘ë‹µ:")
    else:
        print("\nğŸ¤– GPT ì‘ë‹µ:")
    print(resp.content)
