#!/usr/bin/env python3
"""
DOCX â†’ index.json ë³€í™˜ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
ì‚¬ìš©ë²•: python run_docx_to_index.py [ì˜µì…˜] <docx_directory>
"""
import argparse
import os
import sys
import json
from typing import List, Dict, Any

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

try:
    from improved_index_generator import generate_improved_index
except ImportError:
    # ìƒëŒ€ import ì‹œë„
    try:
        from .improved_index_generator import generate_improved_index
    except ImportError:
        print("âŒ ì˜¤ë¥˜: improved_index_generator ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(
        description="DOCX íŒŒì¼ë“¤ì„ index.json í˜•íƒœë¡œ ë³€í™˜",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì œ:
  python run_docx_to_index.py data/docx
  python run_docx_to_index.py data/docx -o output.json
  python run_docx_to_index.py data/docx --compare data/index.json
  python run_docx_to_index.py data/docx --analyze
        """
    )
    
    parser.add_argument(
        'directory',
        help='DOCX íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ'
    )
    
    parser.add_argument(
        '-o', '--output',
        help='ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: <directory>/converted_index.json)',
        default=None
    )
    
    parser.add_argument(
        '--compare',
        help='ë¹„êµí•  ê¸°ì¡´ index.json íŒŒì¼ ê²½ë¡œ',
        default=None
    )
    
    parser.add_argument(
        '--analyze',
        action='store_true',
        help='ìƒì„±ëœ ë°ì´í„°ì˜ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ ì¶œë ¥'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='ìƒì„¸í•œ ë¡œê·¸ ì¶œë ¥'
    )
    
    args = parser.parse_args()
    
    # ì…ë ¥ ê²€ì¦
    if not os.path.isdir(args.directory):
        print(f"âŒ ì˜¤ë¥˜: ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.directory}")
        sys.exit(1)
    
    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    if not args.output:
        # data/json ë””ë ‰í† ë¦¬ê°€ ìˆìœ¼ë©´ ê·¸ê³³ì—, ì—†ìœ¼ë©´ ì…ë ¥ ë””ë ‰í† ë¦¬ì— ìƒì„±
        json_dir = "data/json"
        if os.path.exists(json_dir) and os.path.isdir(json_dir):
            args.output = os.path.join(json_dir, "converted_index.json")
        else:
            # data/json ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            try:
                os.makedirs(json_dir, exist_ok=True)
                args.output = os.path.join(json_dir, "converted_index.json")
                print(f"ğŸ“ data/json ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âš ï¸  data/json ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨, ì…ë ¥ ë””ë ‰í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤: {e}")
                args.output = os.path.join(args.directory, "converted_index.json")
    
    # DOCX â†’ index.json ë³€í™˜
    print("ğŸ”„ DOCX íŒŒì¼ë“¤ì„ index.json í˜•íƒœë¡œ ë³€í™˜ ì¤‘...")
    try:
        result = generate_improved_index(args.directory, args.output)
        
        if not result:
            print("âŒ ë³€í™˜í•  DOCX íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)
        
        print(f"âœ… ë³€í™˜ ì™„ë£Œ: {args.output}")
        
        # ê²°ê³¼ ìš”ì•½
        total_items = sum(len(item['data']) for item in result)
        print(f"ğŸ“Š ë³€í™˜ ê²°ê³¼: {len(result)}ê°œ íŒŒì¼, ì´ {total_items}ê°œ í•­ëª©")
        
        for item in result:
            print(f"   - {item['filename']}: {len(item['data'])}ê°œ í•­ëª©")
        
        # ë¶„ì„ ì˜µì…˜
        if args.analyze:
            analyze_structure(result)
        
        # ë¹„êµ ì˜µì…˜
        if args.compare:
            compare_with_original(result, args.compare)
        
    except Exception as e:
        print(f"âŒ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


def analyze_structure(data: List[Dict[str, Any]]):
    """ìƒì„±ëœ ë°ì´í„°ì˜ êµ¬ì¡° ë¶„ì„"""
    print("\nğŸ“ˆ êµ¬ì¡° ë¶„ì„ ê²°ê³¼:")
    
    for file_item in data:
        filename = file_item['filename']
        items = file_item['data']
        
        print(f"\nğŸ“„ {filename}:")
        
        # í†µê³„ ê³„ì‚°
        title_count = sum(1 for item in items if item.get('title', '').strip())
        heading_count = sum(1 for item in items if item.get('heading', '').strip())
        section_count = sum(1 for item in items if item.get('section', '').strip())
        
        print(f"   ğŸ“‘ ì „ì²´ í•­ëª©: {len(items)}ê°œ")
        print(f"   ğŸ“‹ Title í•­ëª©: {title_count}ê°œ")
        print(f"   ğŸ“ Heading í•­ëª©: {heading_count}ê°œ")
        print(f"   ğŸ“Œ Section í•­ëª©: {section_count}ê°œ")
        
        # ê³ ìœ  titleë“¤ ì¶œë ¥
        unique_titles = set(item['title'] for item in items if item.get('title', '').strip())
        if unique_titles:
            print(f"   ğŸ·ï¸  ê³ ìœ  Titleë“¤ ({len(unique_titles)}ê°œ):")
            for title in sorted(unique_titles)[:5]:  # ì²˜ìŒ 5ê°œë§Œ
                print(f"      - {title}")
            if len(unique_titles) > 5:
                print(f"      ... ë° {len(unique_titles) - 5}ê°œ ë”")


def compare_with_original(generated: List[Dict[str, Any]], original_path: str):
    """ê¸°ì¡´ index.jsonê³¼ ë¹„êµ"""
    print(f"\nğŸ” ì›ë³¸ íŒŒì¼ê³¼ ë¹„êµ: {original_path}")
    
    try:
        with open(original_path, 'r', encoding='utf-8') as f:
            original = json.load(f)
        
        print("ğŸ“Š ë¹„êµ ê²°ê³¼:")
        
        # íŒŒì¼ ê°œìˆ˜ ë¹„êµ
        print(f"   íŒŒì¼ ê°œìˆ˜: ì›ë³¸ {len(original)}ê°œ vs ìƒì„±ë¨ {len(generated)}ê°œ")
        
        # ê° íŒŒì¼ë³„ í•­ëª© ìˆ˜ ë¹„êµ
        original_dict = {item['filename']: len(item['data']) for item in original}
        generated_dict = {item['filename']: len(item['data']) for item in generated}
        
        all_files = set(original_dict.keys()) | set(generated_dict.keys())
        
        for filename in sorted(all_files):
            orig_count = original_dict.get(filename, 0)
            gen_count = generated_dict.get(filename, 0)
            
            if orig_count == 0:
                print(f"   + {filename}: ìƒˆë¡œ ìƒì„±ë¨ ({gen_count}ê°œ)")
            elif gen_count == 0:
                print(f"   - {filename}: ëˆ„ë½ë¨ (ì›ë³¸ {orig_count}ê°œ)")
            else:
                diff = gen_count - orig_count
                diff_str = f"(+{diff})" if diff > 0 else f"({diff})" if diff < 0 else "(ë™ì¼)"
                print(f"   ğŸ“„ {filename}: ì›ë³¸ {orig_count}ê°œ â†’ ìƒì„± {gen_count}ê°œ {diff_str}")
        
        # êµ¬ì¡° ìœ ì‚¬ì„± ì²´í¬
        if generated and original:
            check_structure_similarity(generated[0]['data'][:3], original[0]['data'][:3])
        
    except FileNotFoundError:
        print(f"âŒ ì›ë³¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {original_path}")
    except json.JSONDecodeError:
        print(f"âŒ ì›ë³¸ íŒŒì¼ì´ ìœ íš¨í•œ JSONì´ ì•„ë‹™ë‹ˆë‹¤: {original_path}")


def check_structure_similarity(generated_sample: List[Dict], original_sample: List[Dict]):
    """êµ¬ì¡° ìœ ì‚¬ì„± í™•ì¸"""
    print("   ğŸ” êµ¬ì¡° ìœ ì‚¬ì„± ê²€ì‚¬ (ì²« 3ê°œ í•­ëª©):")
    
    for i, (gen_item, orig_item) in enumerate(zip(generated_sample, original_sample), 1):
        print(f"      í•­ëª© {i}:")
        
        # í•„ë“œ ì¡´ì¬ ì—¬ë¶€ ë¹„êµ
        gen_fields = set(gen_item.keys())
        orig_fields = set(orig_item.keys())
        
        if gen_fields == orig_fields:
            print(f"        âœ… í•„ë“œ êµ¬ì¡° ì¼ì¹˜: {sorted(gen_fields)}")
        else:
            missing = orig_fields - gen_fields
            extra = gen_fields - orig_fields
            if missing:
                print(f"        âš ï¸  ëˆ„ë½ëœ í•„ë“œ: {sorted(missing)}")
            if extra:
                print(f"        â• ì¶”ê°€ëœ í•„ë“œ: {sorted(extra)}")


if __name__ == "__main__":
    main()
