#!/usr/bin/env python3
"""
CLI ê¸°ë°˜ í†µí•© RAG ì‹œìŠ¤í…œ
- ê¸°ì¡´ unified_rag_refactored.pyì˜ core ë¡œì§ ì¬ì‚¬ìš©
- ëŒ€í™”í˜• CLI ì¸í„°í˜ì´ìŠ¤ ì œê³µ
- ëª¨ë¸ ì„ íƒ ë° RAG ì§ˆì˜ ì‘ë‹µ
"""

import os
import sys
import argparse
import textwrap
import time
from datetime import datetime
from typing import Optional, Dict, Any
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

# ê¸°ì¡´ ëª¨ë“ˆ ì„í¬íŠ¸
from core.config import LLM_MODELS, HUGGINGFACE_EMBEDDINGS_AVAILABLE, UPSTAGE_AVAILABLE, OLLAMA_AVAILABLE
from core.models import ModelFactory
from core.rag import create_rag_chain
from core.chat_history import ChatHistoryManager, CLIChatHistoryInterface
from utils.elasticsearch import ElasticsearchManager

# Elasticsearch ê°€ìš©ì„± í™•ì¸
try:
    from elasticsearch import Elasticsearch
    ELASTICSEARCH_AVAILABLE = True
except ImportError:
    ELASTICSEARCH_AVAILABLE = False

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class PerformanceTimer:
    """ì„±ëŠ¥ ì¸¡ì •ìš© ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    def __init__(self, task_name: str, show_progress: bool = True):
        self.task_name = task_name
        self.show_progress = show_progress
        self.start_time = None
        
    def __enter__(self):
        if self.show_progress:
            print(f"â±ï¸ {self.task_name} ì‹œì‘...")
        self.start_time = time.time()
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        elapsed = time.time() - self.start_time
        if self.show_progress:
            print(f"âœ… {self.task_name} ì™„ë£Œ ({elapsed:.2f}ì´ˆ)")

class CLIRAGSystem:
    """CLI ê¸°ë°˜ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.es_manager = None
        self.model_factory = ModelFactory()
        self.rag_chain = None
        self.embedding_model = None
        self.llm_model = None
        self.model_choice = None
        self.top_k = 5
        
        # ê³µí†µ ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ì ì‚¬ìš©
        self.chat_manager = ChatHistoryManager(max_history=10)
        self.chat_interface = CLIChatHistoryInterface(self.chat_manager)
        
    def check_dependencies(self) -> bool:
        """ì˜ì¡´ì„± í™•ì¸"""
        print("ğŸ” ì‹œìŠ¤í…œ ì˜ì¡´ì„± í™•ì¸ ì¤‘...")
        
        issues = []
        
        if not ELASTICSEARCH_AVAILABLE:
            issues.append("âŒ Elasticsearch ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        if not HUGGINGFACE_EMBEDDINGS_AVAILABLE:
            issues.append("âŒ HuggingFace ì„ë² ë”© ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Elasticsearch ì„œë²„ ì—°ê²° í™•ì¸
        try:
            es_manager = ElasticsearchManager()
            is_connected, connection_msg = es_manager.check_connection()
            if not is_connected:
                issues.append(f"âŒ Elasticsearch ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {connection_msg}")
        except Exception as e:
            issues.append(f"âŒ Elasticsearch ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        
        # Ollama ì„œë²„ ì—°ê²° í™•ì¸ ì¶”ê°€
        try:
            from core.rag import check_ollama_connection
            ollama_connected, ollama_message = check_ollama_connection()
            if not ollama_connected:
                issues.append(f"âŒ Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {ollama_message}")
            else:
                print(f"âœ… {ollama_message}")
        except Exception as e:
            issues.append(f"âŒ Ollama ì—°ê²° í™•ì¸ ì˜¤ë¥˜: {str(e)}")
        
        if issues:
            print("\n".join(issues))
            print("\ní•´ê²° ë°©ë²•:")
            print("1. Python íŒ¨í‚¤ì§€ ì„¤ì¹˜:")
            print("   pip install -r requirements.txt")
            print("   ë˜ëŠ”: pip install -r requirements_unified.txt")
            print("2. Elasticsearch ì„œë²„ ì‹œì‘:")
            print("   ./setup.sh               # Docker + Elasticsearch ìë™ ì‹œì‘")
            print("   ë˜ëŠ”: ./start.sh         # ì „ì²´ ì‹œìŠ¤í…œ ìë™ ì‹œì‘")
            print("   ë˜ëŠ”: docker-compose up -d elasticsearch")
            print("3. Ollama ì„¤ì¹˜ ë° ì‹œì‘:")
            print("   - Ollama ë‹¤ìš´ë¡œë“œ: https://ollama.ai/download")
            print("   - Ollama ì‹œì‘: ollama serve")
            print("   - ëª¨ë¸ ì„¤ì¹˜: ollama pull qwen2:7b")
            print("   - í™•ì¸: ollama list")
            print("4. Ollama ëª¨ë¸ í™•ì¸:")
            print("   ollama list              # ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸")
            print("   ollama pull solar:10.7b  # SOLAR ëª¨ë¸ ì„¤ì¹˜")
            return False
        
        print("âœ… ëª¨ë“  ì˜ì¡´ì„±ì´ ì •ìƒì…ë‹ˆë‹¤.")
        return True
    
    def show_available_models(self) -> Dict[str, Any]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ í‘œì‹œ"""
        print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ LLM ëª¨ë¸:")
        
        available_models = self.model_factory.get_available_models()
        
        if not available_models:
            print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        model_list = []
        for i, (key, config) in enumerate(available_models.items(), 1):
            print(f"{i}. {config['name']} (í‚¤: {key})")
            model_list.append((key, config))
        
        return dict(model_list)
    
    def select_model(self, model_key: Optional[str] = None) -> bool:
        """ëª¨ë¸ ì„ íƒ"""
        available_models = self.show_available_models()
        
        if not available_models:
            return False
        
        if model_key:
            # CLI ì¸ìë¡œ ëª¨ë¸ì´ ì§€ì •ëœ ê²½ìš°
            if model_key in available_models:
                self.model_choice = model_key
                print(f"âœ… ì„ íƒëœ ëª¨ë¸: {available_models[model_key]['name']}")
                return True
            else:
                print(f"âŒ ëª¨ë¸ '{model_key}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
        
        # ëŒ€í™”í˜• ëª¨ë¸ ì„ íƒ
        while True:
            try:
                choice = input("\nëª¨ë¸ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-{}): ".format(len(available_models)))
                choice_idx = int(choice) - 1
                
                if 0 <= choice_idx < len(available_models):
                    model_keys = list(available_models.keys())
                    self.model_choice = model_keys[choice_idx]
                    selected_model = available_models[self.model_choice]
                    print(f"âœ… ì„ íƒëœ ëª¨ë¸: {selected_model['name']}")
                    return True
                else:
                    print("âŒ ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤.")
            except (ValueError, KeyboardInterrupt):
                print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return False
    
    def set_search_parameters(self, top_k: Optional[int] = None):
        """ê²€ìƒ‰ ë§¤ê°œë³€ìˆ˜ ì„¤ì •"""
        if top_k:
            self.top_k = top_k
            print(f"âœ… Top-K ì„¤ì •: {self.top_k}")
            return
        
        print(f"\ní˜„ì¬ Top-K ì„¤ì •: {self.top_k}")
        try:
            new_k = input("ìƒˆë¡œìš´ Top-K ê°’ì„ ì…ë ¥í•˜ì„¸ìš” (ì—”í„°: ê¸°ë³¸ê°’ ìœ ì§€): ").strip()
            if new_k:
                self.top_k = int(new_k)
                print(f"âœ… Top-Kê°€ {self.top_k}ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except ValueError:
            print("âŒ ì˜ëª»ëœ ê°’ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ìœ ì§€í•©ë‹ˆë‹¤.")
    
    def _auto_index_pdfs(self) -> bool:
        """PDF íŒŒì¼ ìë™ ì¸ë±ì‹± - ì„±ëŠ¥ ìµœì í™”"""
        from core.config import PDF_DIR, INDEX_NAME
        from elasticsearch import Elasticsearch
        
        # PDF ë””ë ‰í† ë¦¬ í™•ì¸
        if not os.path.exists(PDF_DIR):
            print(f"ğŸ“ PDF ë””ë ‰í† ë¦¬({PDF_DIR})ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒì„±í•©ë‹ˆë‹¤...")
            os.makedirs(PDF_DIR, exist_ok=True)
            print("ğŸ“„ PDF íŒŒì¼ì´ ì—†ì–´ì„œ ì¸ë±ì‹±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return True
        
        # PDF íŒŒì¼ ëª©ë¡ í™•ì¸
        pdf_files = self.es_manager.list_pdfs(PDF_DIR)
        if not pdf_files:
            print("ğŸ“„ PDF íŒŒì¼ì´ ì—†ì–´ì„œ ì¸ë±ì‹±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return True
        
        # ì¸ë±ìŠ¤ ì¡´ì¬ ë° ë¬¸ì„œ ìˆ˜ í™•ì¸ (ìµœì í™”)
        try:
            es = Elasticsearch("http://localhost:9200", timeout=10)
            index_exists = es.indices.exists(index=INDEX_NAME)
            
            if index_exists:
                doc_count = es.count(index=INDEX_NAME).get("count", 0)
                if doc_count > 0:
                    print(f"ğŸ“š ê¸°ì¡´ ì¸ë±ìŠ¤ì— {doc_count}ê°œ ë¬¸ì„œê°€ ìˆìŠµë‹ˆë‹¤. ì¸ë±ì‹±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                    return True
        except Exception as check_error:
            print(f"âš ï¸ ì¸ë±ìŠ¤ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(check_error)}, ì¸ë±ì‹±ì„ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
        
        # PDF íŒŒì¼ ì¸ë±ì‹± ì‹¤í–‰
        print(f"ğŸ“„ {len(pdf_files)}ê°œ PDF íŒŒì¼ì„ ìë™ ì¸ë±ì‹±í•©ë‹ˆë‹¤...")
        for pdf_file in pdf_files:
            print(f"  - {os.path.basename(pdf_file)}")
        
        try:
            # ê°„ë‹¨í•œ íŠ¸ë˜ì»¤ ìƒì„± (CLIìš©) - ì§„í–‰ ìƒí™© í‘œì‹œ ê°œì„ 
            class SimpleTracker:
                def track_preprocessing_stage(self, stage):
                    print(f"ğŸ”„ {stage}")
                def end_preprocessing_stage(self, stage):
                    print(f"âœ… {stage} ì™„ë£Œ")
            
            tracker = SimpleTracker()
            
            indexing_start = time.time()
            success, message = self.es_manager.index_pdfs(pdf_files, self.embedding_model, tracker)
            indexing_time = time.time() - indexing_start
            
            if success:
                print(f"âœ… PDF ìë™ ì¸ë±ì‹± ì™„ë£Œ: {message} ({indexing_time:.2f}ì´ˆ)")
                return True
            else:
                print(f"âŒ PDF ìë™ ì¸ë±ì‹± ì‹¤íŒ¨: {message}")
                return False
                
        except Exception as e:
            print(f"âŒ PDF ìë™ ì¸ë±ì‹± ì˜¤ë¥˜: {str(e)}")
            return False
    
    def initialize_rag_system(self) -> bool:
        """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” - ì„±ëŠ¥ ìµœì í™”"""
        print("\nğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        init_start_time = time.time()
        
        # 1. Elasticsearch ì—°ê²°
        try:
            with PerformanceTimer("Elasticsearch ì—°ê²°"):
                self.es_manager = ElasticsearchManager()
                is_connected, connection_msg = self.es_manager.check_connection()
                if not is_connected:
                    print(f"âŒ Elasticsearch ì—°ê²° ì‹¤íŒ¨: {connection_msg}")
                    return False
                print(f"âœ… Elasticsearch ì—°ê²° ì„±ê³µ: {connection_msg}")
        except Exception as e:
            print(f"âŒ Elasticsearch ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
            return False
        
        # 2. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        try:
            with PerformanceTimer("BGE-M3 ì„ë² ë”© ëª¨ë¸ ë¡œë“œ"):
                self.embedding_model = self.model_factory.create_embedding_model()
                if not self.embedding_model:
                    print("âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
                    return False
                print("âœ… BGE-M3 ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ëª¨ë¸ ì˜¤ë¥˜: {str(e)}")
            return False
        
        # 2.5. PDF ìë™ ì¸ë±ì‹± í™•ì¸ ë° ì‹¤í–‰ (ìµœì í™”: ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥)
        try:
            with PerformanceTimer("PDF ì¸ë±ì‹± í™•ì¸", False):
                success = self._auto_index_pdfs()
                if not success:
                    print("âš ï¸ PDF ìë™ ì¸ë±ì‹± ì‹¤íŒ¨, ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
        except Exception as e:
            print(f"âš ï¸ PDF ìë™ ì¸ë±ì‹± ì˜¤ë¥˜: {str(e)}, ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
        
        # 3. LLM ëª¨ë¸ ë¡œë“œ (ê°€ì¥ ì‹œê°„ì´ ë§ì´ ê±¸ë¦¬ëŠ” ë¶€ë¶„)
        try:
            with PerformanceTimer(f"{self.model_choice} LLM ëª¨ë¸ ë¡œë“œ"):
                self.llm_model, status = self.model_factory.create_llm_model(self.model_choice)
                if not self.llm_model:
                    print(f"âŒ LLM ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {status}")
                    return False
                print(f"âœ… {status}")
        except Exception as e:
            print(f"âŒ LLM ëª¨ë¸ ì˜¤ë¥˜: {str(e)}")
            return False
        
        # 4. RAG ì²´ì¸ ìƒì„±
        try:
            with PerformanceTimer("RAG ì²´ì¸ ìƒì„±"):
                self.rag_chain, success = create_rag_chain(
                    embeddings=self.embedding_model,
                    llm_model=self.llm_model,
                    top_k=self.top_k
                )
                if not self.rag_chain:
                    print(f"âŒ RAG ì²´ì¸ ìƒì„± ì‹¤íŒ¨: {success}")
                    return False
                print("âœ… RAG ì²´ì¸ ìƒì„± ì„±ê³µ")
        except Exception as e:
            print(f"âŒ RAG ì²´ì¸ ì˜¤ë¥˜: {str(e)}")
            return False
        
        total_init_time = time.time() - init_start_time
        print(f"\nğŸ‰ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ! (ì´ {total_init_time:.2f}ì´ˆ)")
        
        # ì„±ëŠ¥ ìµœì í™” íŒ ì œê³µ
        if total_init_time > 30:  # 30ì´ˆ ì´ìƒ ê±¸ë¦° ê²½ìš°
            print("\nğŸ’¡ ì´ˆê¸°í™” ì‹œê°„ ìµœì í™” íŒ:")
            print("   - ë” ì‘ì€ LLM ëª¨ë¸ ì‚¬ìš© (ì˜ˆ: qwen2:1.5b)")
            print("   - SSD ì‚¬ìš© ë° ì¶©ë¶„í•œ RAM í™•ë³´")
            print("   - Ollama ëª¨ë¸ ì‚¬ì „ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ í™•ì¸")
        
        return True
    
    def show_system_info(self):
        """ì‹œìŠ¤í…œ ì •ë³´ í‘œì‹œ - ì„±ëŠ¥ ì •ë³´ í¬í•¨"""
        print("\n" + "="*60)
        print("ğŸ¤– í†µí•© RAG ì‹œìŠ¤í…œ - CLI ëª¨ë“œ")
        print("="*60)
        print(f"ğŸ“‹ ì„ íƒëœ ëª¨ë¸: {LLM_MODELS[self.model_choice]['name']}")
        print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: Top-{self.top_k}")
        print(f"ğŸ—„ï¸ ì„ë² ë”©: BGE-M3")
        print(f"ğŸ”— ë²¡í„° DB: Elasticsearch (localhost:9200)")
        
        # ì„±ëŠ¥ ìµœì í™” íŒ
        print("\nğŸ’¡ ì„±ëŠ¥ ìµœì í™” íŒ:")
        if self.top_k > 10:
            print(f"   âš ï¸ Top-K ê°’ì´ {self.top_k}ë¡œ ë†’ìŠµë‹ˆë‹¤. 5-10 ì¶”ì²œ")
        else:
            print(f"   âœ… Top-K ê°’ ({self.top_k})ì´ ì ì ˆí•©ë‹ˆë‹¤.")
        
        print("   ğŸ“ ì‘ë‹µ ì†ë„ ê°œì„ :")
        print("      - ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš© (qwen2:1.5b)")
        print("      - Top-K ê°’ ì¤„ì´ê¸° (3-5 ì¶”ì²œ)")
        print("      - SSD ì‚¬ìš© ë° ì¶©ë¶„í•œ RAM í™•ë³´")
        print("="*60)
    
    def process_query(self, query: str) -> Optional[str]:
        """ì§ˆì˜ ì²˜ë¦¬ - ì„±ëŠ¥ ìµœì í™” ë° ì¸¡ì • í¬í•¨"""
        if not self.rag_chain:
            print("âŒ RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        total_start_time = time.time()
        
        try:
            print(f"\nğŸ” ì§ˆì˜ ì²˜ë¦¬ ì¤‘: {query}")
            
            # 1. ëŒ€í™” ê¸°ë¡ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ì„±ëŠ¥ ì¸¡ì •)
            with PerformanceTimer("ëŒ€í™” ê¸°ë¡ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±", False):
                context_query = self.chat_manager.build_context_query(query)
            
            # 2. RAG ì²´ì¸ ì‹¤í–‰ (ì„±ëŠ¥ ì¸¡ì •)
            print("â±ï¸ RAG ì²´ì¸ ì‹¤í–‰ ì¤‘...")
            rag_start_time = time.time()
            
            # ë²¡í„° ê²€ìƒ‰ ë‹¨ê³„
            print("  ğŸ“š ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
            search_start = time.time()
            
            response = self.rag_chain({"query": context_query})
            
            rag_elapsed = time.time() - rag_start_time
            total_elapsed = time.time() - total_start_time
            
            # ì„±ëŠ¥ ì •ë³´ ì¶œë ¥
            print(f"  âœ… RAG ì²˜ë¦¬ ì™„ë£Œ ({rag_elapsed:.2f}ì´ˆ)")
            print(f"  ğŸ“Š ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {total_elapsed:.2f}ì´ˆ")
            
            # ì‘ë‹µ ì²˜ë¦¬
            answer = self._extract_answer(response)
            
            if answer:
                # ê³µí†µ ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ìì— ì¶”ê°€ (ì›ë³¸ ì§ˆë¬¸ê³¼ ë‹µë³€ë§Œ)
                self.chat_manager.add_chat(query, answer)
                
                # ì„±ëŠ¥ í†µê³„ í‘œì‹œ
                if rag_elapsed > 10:  # 10ì´ˆ ì´ìƒ ê±¸ë¦° ê²½ìš° ì„±ëŠ¥ íŒ ì œê³µ
                    print(f"âš ï¸ ì‘ë‹µ ì‹œê°„ì´ {rag_elapsed:.2f}ì´ˆë¡œ ëŠë¦½ë‹ˆë‹¤.")
                    print("ğŸ’¡ ì„±ëŠ¥ ê°œì„  íŒ:")
                    print("   - Top-K ê°’ì„ ì¤„ì—¬ë³´ì„¸ìš” (í˜„ì¬: {})".format(self.top_k))
                    print("   - Ollama ëª¨ë¸ì„ ë” ì‘ì€ í¬ê¸°ë¡œ ë³€ê²½í•´ë³´ì„¸ìš”")
                    print("   - SSD ì‚¬ìš© ë° ì¶©ë¶„í•œ RAM í™•ë³´")
                
                return answer
            
            return None
                
        except Exception as e:
            total_elapsed = time.time() - total_start_time
            print(f"âŒ ì§ˆì˜ ì²˜ë¦¬ ì˜¤ë¥˜ ({total_elapsed:.2f}ì´ˆ ê²½ê³¼): {str(e)}")
            return None
    
    def _extract_answer(self, response) -> Optional[str]:
        """ì‘ë‹µì—ì„œ ë‹µë³€ ì¶”ì¶œ"""
        if isinstance(response, dict):
            if 'result' in response:
                return response['result']
            elif 'answer' in response:
                return response['answer']
            else:
                return str(response)
        elif hasattr(response, 'content'):
            return response.content
        elif isinstance(response, str):
            return response
        else:
            return str(response)
    
    def interactive_chat(self):
        """ëŒ€í™”í˜• ì±„íŒ… ëª¨ë“œ - ëŒ€í™” ê¸°ë¡ í¬í•¨"""
        self.show_system_info()
        
        print("\nğŸ’¬ ëŒ€í™”í˜• ì±„íŒ… ëª¨ë“œ ì‹œì‘")
        print("(ì¢…ë£Œ: 'exit', 'quit', ë˜ëŠ” Ctrl+C)")
        print("(ëŒ€í™”ê¸°ë¡ ë³´ê¸°: 'history', ê¸°ë¡ ì‚­ì œ: 'clear')")
        print("-" * 60)
        
        chat_count = 0
        
        while True:
            try:
                # ì‚¬ìš©ì ì…ë ¥
                query = input(f"\n[{chat_count + 1}] ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
                
                if not query:
                    continue
                
                # íŠ¹ìˆ˜ ëª…ë ¹ì–´ ì²˜ë¦¬
                if query.lower() in ['exit', 'quit', 'ì¢…ë£Œ']:
                    print("\nğŸ‘‹ ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                elif query.lower() in ['history', 'ê¸°ë¡', 'íˆìŠ¤í† ë¦¬']:
                    self.chat_interface.show_history()
                    continue
                elif query.lower() in ['clear', 'ì‚­ì œ', 'í´ë¦¬ì–´']:
                    self.chat_interface.clear_history_with_confirmation()
                    continue
                
                # ì§ˆì˜ ì²˜ë¦¬
                response = self.process_query(query)
                
                if response:
                    chat_count += 1
                    from datetime import datetime
                    timestamp = datetime.now().strftime("%H:%M:%S")
                    print(f"\nğŸ¤– ë‹µë³€ [{timestamp}]:")
                    print("-" * 40)
                    
                    # í…ìŠ¤íŠ¸ ë˜í•‘ìœ¼ë¡œ ê°€ë…ì„± í–¥ìƒ
                    wrapped_response = textwrap.fill(response, width=80)
                    print(wrapped_response)
                    print("-" * 40)
                    
                    # ëŒ€í™” ê¸°ë¡ ìš”ì•½ í‘œì‹œ
                    if self.chat_manager.has_history():
                        self.chat_interface.show_status_info()
                else:
                    print("âŒ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def single_query_mode(self, query: str):
        """ë‹¨ì¼ ì§ˆì˜ ëª¨ë“œ"""
        self.show_system_info()
        
        print(f"\nğŸ” ì§ˆì˜: {query}")
        response = self.process_query(query)
        
        if response:
            print(f"\nğŸ¤– ë‹µë³€:")
            print("="*60)
            wrapped_response = textwrap.fill(response, width=80)
            print(wrapped_response)
            print("="*60)
        else:
            print("âŒ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="CLI ê¸°ë°˜ í†µí•© RAG ì‹œìŠ¤í…œ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=textwrap.dedent('''
        ì‚¬ìš© ì˜ˆì‹œ:
          python unified_rag_cli.py                           # ëŒ€í™”í˜• ëª¨ë“œ
          python unified_rag_cli.py --model upstage          # ëª¨ë¸ ì§€ì • í›„ ëŒ€í™”í˜• ëª¨ë“œ  
          python unified_rag_cli.py --query "ì§ˆë¬¸ ë‚´ìš©"       # ë‹¨ì¼ ì§ˆì˜ ëª¨ë“œ
          python unified_rag_cli.py --model solar_10_7b --query "ì§ˆë¬¸" --top-k 10
        ''')
    )
    
    parser.add_argument(
        "--model", "-m",
        type=str,
        help="ì‚¬ìš©í•  LLM ëª¨ë¸ (upstage, solar_10_7b, qwen2, llama3)"
    )
    
    parser.add_argument(
        "--query", "-q",
        type=str,
        help="ì§ˆì˜ í…ìŠ¤íŠ¸ (ë‹¨ì¼ ì§ˆì˜ ëª¨ë“œ)"
    )
    
    parser.add_argument(
        "--top-k", "-k",
        type=int,
        default=5,
        help="ê²€ìƒ‰ ê²°ê³¼ ìƒìœ„ Kê°œ (ê¸°ë³¸ê°’: 5)"
    )
    
    parser.add_argument(
        "--no-check",
        action="store_true",
        help="ì˜ì¡´ì„± ê²€ì‚¬ ê±´ë„ˆë›°ê¸°"
    )
    
    parser.add_argument(
        "--fast",
        action="store_true",
        help="ë¹ ë¥¸ ëª¨ë“œ (ì‘ì€ ëª¨ë¸ ë° ë‚®ì€ Top-K ìë™ ì„¤ì •)"
    )
    
    parser.add_argument(
        "--benchmark",
        action="store_true",
        help="ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ (ìƒì„¸í•œ ì‹œê°„ ì¸¡ì •)"
    )
    
    args = parser.parse_args()
    
    # CLI RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag_system = CLIRAGSystem()
    
    # ë¹ ë¥¸ ëª¨ë“œ ì„¤ì •
    if args.fast:
        print("ğŸš€ ë¹ ë¥¸ ëª¨ë“œ í™œì„±í™”")
        # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        if not args.model:
            args.model = "qwen2"  # ë¹ ë¥¸ ëª¨ë¸ ê¸°ë³¸ ì„ íƒ
        if not hasattr(args, 'top_k') or args.top_k == 5:
            args.top_k = 3  # ë‚®ì€ Top-K ì„¤ì •
        print(f"   - ëª¨ë¸: {args.model}")
        print(f"   - Top-K: {args.top_k}")
    
    # ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ ì„¤ì •
    if args.benchmark:
        print("ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ í™œì„±í™” - ìƒì„¸í•œ ì„±ëŠ¥ ì¸¡ì •")
    
    # ì˜ì¡´ì„± í™•ì¸
    if not args.no_check:
        if not rag_system.check_dependencies():
            print("\nì˜ì¡´ì„± ë¬¸ì œë¡œ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            sys.exit(1)
    
    # ëª¨ë¸ ì„ íƒ
    if not rag_system.select_model(args.model):
        print("\nëª¨ë¸ ì„ íƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    # ê²€ìƒ‰ ë§¤ê°œë³€ìˆ˜ ì„¤ì •
    rag_system.set_search_parameters(args.top_k)
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if not rag_system.initialize_rag_system():
        print("\nRAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    # ì‹¤í–‰ ëª¨ë“œ ê²°ì •
    if args.query:
        # ë‹¨ì¼ ì§ˆì˜ ëª¨ë“œ
        rag_system.single_query_mode(args.query)
    else:
        # ëŒ€í™”í˜• ëª¨ë“œ
        rag_system.interactive_chat()


if __name__ == "__main__":
    main()
